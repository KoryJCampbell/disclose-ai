# =============================================================================
# NIST AI RMF Model Card
# Generated by @legacybridge/modelcard
# Reference: NIST AI 100-1 | OMB M-24-10
# =============================================================================

# --- Card Metadata ---
metadata:
  card_version: "1.0.0"
  created_date: ""          # ISO 8601 date (YYYY-MM-DD)
  last_updated: ""
  status: draft             # draft | review | approved | retired
  classification: unclassified  # unclassified | cui | confidential | secret | top_secret
  schema_version: "1.0.0"

# =============================================================================
# GOVERN — Policies, Processes & Oversight
# NIST AI RMF: Establish governance structures for AI risk management
# =============================================================================
govern:
  # GOVERN 1.1-1.2: Ownership & Accountability
  ownership:
    organization: ""        # Organization responsible for the AI system
    model_owner: ""         # Individual responsible for the model
    email: ""               # Contact email
    chief_ai_officer: ""    # Agency Chief AI Officer (if applicable)
    team: ""                # Team or division

  # GOVERN 1.4-1.5: Approval & Review
  approval:
    authority: ""           # Approval authority name/role
    date: ""                # Approval date (YYYY-MM-DD)
    review_cadence: annually  # monthly | quarterly | semi-annually | annually
    next_review: ""         # Next scheduled review date

  # GOVERN 1.7: Incident Response
  incident_response:
    has_plan: false
    contact: ""             # Incident response contact
    escalation_path: ""     # Escalation path description
    reporting_url: ""       # Incident reporting URL

  # GOVERN 6.1-6.2: Supply Chain Risk Management
  supply_chain:
    third_party_components: []
    #   - name: ""
    #     version: ""
    #     provider: ""
    #     license: ""
    #     risk_assessment: ""
    open_source_components: []
    data_providers: []

# =============================================================================
# MAP — Context & Risk Identification
# NIST AI RMF: Identify context and risks related to the AI system
# =============================================================================
map:
  # MAP 1.1: Model Overview
  model_overview:
    name: ""                # Model name
    version: ""             # Model version
    type: ""                # e.g., classification, NLP, computer vision
    architecture: ""        # e.g., transformer, CNN, random forest
    description: ""         # High-level description
    framework: ""           # e.g., PyTorch, TensorFlow, scikit-learn
    size: ""                # Model size (parameters, file size)
    input_format: ""        # Expected input format
    output_format: ""       # Output format

  # MAP 2.1-2.3: Intended Use
  intended_use:
    use_cases: []           # Primary intended use cases
    users: []               # Intended users
    deployment_context: ""  # production | research | internal
    interaction_mode: human-in-the-loop  # autonomous | semi-autonomous | human-in-the-loop | decision-support

  # MAP 2.2 / MAP 5.1: Out-of-Scope Uses
  out_of_scope:
    excluded_uses: []       # Explicitly excluded use cases
    misuse_risks: []        # Known misuse risks
    geographic_limitations: ""

  # MAP 3.1 / GOVERN 1.1: Regulatory Context
  # ⚠️ OMB M-24-10: Rights-impacting and safety-impacting AI require enhanced documentation
  regulatory:
    laws: []                # Applicable laws and regulations
    policies: []            # Applicable agency policies
    ato_status: none        # none | in_progress | granted | expired
    rights_impacting: false # Per OMB M-24-10
    safety_impacting: false # Per OMB M-24-10

  # MAP 5.1-5.2: Impact Assessment
  impact_assessment:
    affected_populations: []
    benefits: []
    harms: []
    severity: ""            # negligible | minor | moderate | significant | critical
    likelihood: ""          # rare | unlikely | possible | likely | almost_certain

# =============================================================================
# MEASURE — Risk Assessment & Analysis
# NIST AI RMF: Assess, analyze, and track identified risks
# =============================================================================
measure:
  # MEASURE 2.6-2.7: Training Data
  training_data:
    description: ""
    sources: []
    #   - name: ""
    #     description: ""
    #     size: ""
    #     license: ""
    #     collection_method: ""
    known_biases: []
    pii_present: false
    preprocessing: ""

  # MEASURE 2.6: Evaluation Data
  evaluation_data:
    description: ""
    methodology: ""
    test_set_size: ""

  # MEASURE 2.5: Performance Metrics
  performance_metrics:
    metrics: []
    #   - name: ""
    #     value: ""
    #     description: ""
    #     threshold: ""
    #     confidence_interval: ""
    primary_metric: ""
    disaggregated_results: []
    #   - group: ""
    #     metrics:
    #       - name: ""
    #         value: ""

  # MEASURE 2.11: Bias & Fairness
  bias_evaluation:
    conducted: false
    methodology: ""
    protected_attributes: []
    fairness_metrics: []
    findings: ""

  # MEASURE 2.7-2.8: Robustness & Security
  robustness:
    adversarial_testing: false
    stress_testing: false
    data_drift_monitoring: false
    findings: ""

# =============================================================================
# MANAGE — Risk Prioritization & Response
# NIST AI RMF: Prioritize and act upon identified risks
# =============================================================================
manage:
  # MANAGE 2.2: Known Limitations
  limitations:
    known_limitations: []
    failure_modes: []
    edge_cases: []

  # MANAGE 2.1 / 2.3: Mitigation Strategies
  mitigations:
    strategies: []
    #   - risk: ""
    #     strategy: ""
    #     status: planned   # planned | in_progress | implemented | verified
    #     responsible_party: ""
    human_oversight_plan: ""

  # MANAGE 4.1: Post-Deployment Monitoring
  monitoring:
    has_plan: false
    frequency: ""           # real-time | daily | weekly | monthly | quarterly
    alert_thresholds: []
    #   - metric: ""
    #     threshold: ""
    #     action: ""
    dashboard_url: ""

  # MANAGE 4.2 / 3.2: Lifecycle Management
  lifecycle:
    update_frequency: ""
    retraining_triggers: []
    retirement_criteria: []
    versioning_strategy: ""
